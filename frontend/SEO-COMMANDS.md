# üîß Commandes SEO Utiles

## üìã V√©rification Avant le Lancement

### V√©rifier le Sitemap
```bash
# V√©rifier que le sitemap est accessible
curl https://grandson-project.com/sitemap.xml

# Valider le sitemap XML
curl https://grandson-project.com/sitemap.xml | xmllint --format -
```

### V√©rifier Robots.txt
```bash
# V√©rifier que robots.txt est accessible
curl https://grandson-project.com/robots.txt

# Afficher le contenu
cat frontend/app/robots.ts
```

### V√©rifier les M√©tadonn√©es
```bash
# Extraire les m√©tadonn√©es de la page d'accueil
curl -s https://grandson-project.com | grep -E '<title>|<meta name="description"'

# V√©rifier les Open Graph tags
curl -s https://grandson-project.com | grep -E 'og:title|og:description|og:image'
```

### V√©rifier les Structured Data
```bash
# Extraire les schemas JSON-LD
curl -s https://grandson-project.com | grep -A 20 'application/ld+json'
```

---

## üèóÔ∏è Build et D√©ploiement

### Build pour Production
```bash
cd frontend
npm run build

# V√©rifier les erreurs de build
npm run build 2>&1 | grep -i error
```

### Tester Localement
```bash
cd frontend
npm run build
npm run start

# Ouvrir dans le navigateur
# http://localhost:3000
```

### V√©rifier les Performances
```bash
# Lighthouse CLI
npm install -g @lhci/cli@latest

# Ex√©cuter Lighthouse
lhci autorun

# Ou utiliser Chrome DevTools
# 1. Ouvrir Chrome DevTools (F12)
# 2. Aller √† l'onglet Lighthouse
# 3. Cliquer sur "Analyze page load"
```

---

## üîç V√©rification SEO

### V√©rifier les Liens Cass√©s
```bash
# Utiliser wget pour v√©rifier les liens
wget --spider -r -o /tmp/wget.log https://grandson-project.com
grep "HTTP" /tmp/wget.log | grep -v "200 OK"

# Ou utiliser curl
for url in $(curl -s https://grandson-project.com | grep -oP 'href="\K[^"]+'); do
  echo "Checking $url"
  curl -s -o /dev/null -w "%{http_code}" "$url"
done
```

### V√©rifier les Images
```bash
# V√©rifier que toutes les images ont un alt text
curl -s https://grandson-project.com | grep -E '<img[^>]*>' | grep -v 'alt='

# V√©rifier les images manquantes
curl -s https://grandson-project.com | grep -oP 'src="\K[^"]+' | while read url; do
  curl -s -o /dev/null -w "$url: %{http_code}\n" "$url"
done
```

### V√©rifier les Redirects
```bash
# V√©rifier les redirects 301
curl -I https://grandson-project.com/old-page
# Devrait retourner 301 ou 302

# V√©rifier la cha√Æne de redirects
curl -L -I https://grandson-project.com/old-page
```

---

## üìä Monitoring et Analytics

### V√©rifier les Core Web Vitals
```bash
# Utiliser PageSpeed Insights API
curl "https://www.googleapis.com/pagespeedonline/v5/runPagespeed?url=https://grandson-project.com&key=YOUR_API_KEY"

# Ou utiliser web-vitals npm package
npm install web-vitals
```

### V√©rifier le Trafic Organique
```bash
# Utiliser Google Search Console API
# N√©cessite une authentification OAuth2

# Exemple avec curl
curl -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  "https://www.googleapis.com/webmasters/v3/sites/https%3A%2F%2Fgrandson-project.com%2F/searchAnalytics/query" \
  -X POST \
  -d '{"startDate":"2025-01-01","endDate":"2025-01-31","dimensions":["query"]}'
```

---

## üîê S√©curit√© SEO

### V√©rifier le HTTPS
```bash
# V√©rifier que HTTPS est activ√©
curl -I https://grandson-project.com
# Devrait retourner 200 OK

# V√©rifier le certificat SSL
openssl s_client -connect grandson-project.com:443 -servername grandson-project.com
```

### V√©rifier les Headers de S√©curit√©
```bash
# V√©rifier les headers de s√©curit√©
curl -I https://grandson-project.com | grep -E 'X-Frame-Options|X-Content-Type-Options|Strict-Transport-Security'

# V√©rifier avec curl verbose
curl -v https://grandson-project.com 2>&1 | grep -E '^<|^>'
```

---

## üìù Maintenance Continue

### V√©rifier les Erreurs de Crawl
```bash
# V√©rifier les logs du serveur
tail -f /var/log/nginx/access.log | grep "404\|500"

# Ou utiliser Google Search Console API
curl -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  "https://www.googleapis.com/webmasters/v3/sites/https%3A%2F%2Fgrandson-project.com%2F/crawlIssues"
```

### Mettre √† Jour le Sitemap
```bash
# Le sitemap est g√©n√©r√© automatiquement par Next.js
# Mais vous pouvez le r√©g√©n√©rer manuellement

# Red√©ployer le site
npm run build
npm run start

# Ou soumettre manuellement √† Google Search Console
```

### V√©rifier les Backlinks
```bash
# Utiliser des outils comme Ahrefs, SEMrush, ou Moz
# Ou utiliser l'API Google Search Console

curl -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  "https://www.googleapis.com/webmasters/v3/sites/https%3A%2F%2Fgrandson-project.com%2F/sitemaps"
```

---

## üöÄ D√©ploiement sur Vercel

### D√©ployer avec Vercel CLI
```bash
# Installer Vercel CLI
npm i -g vercel

# D√©ployer
vercel

# D√©ployer en production
vercel --prod
```

### Configurer les Variables d'Environnement
```bash
# Ajouter les variables SEO
vercel env add NEXT_PUBLIC_SITE_URL
vercel env add NEXT_PUBLIC_GOOGLE_ANALYTICS_ID
vercel env add NEXT_PUBLIC_GOOGLE_SITE_VERIFICATION

# V√©rifier les variables
vercel env list
```

### V√©rifier le D√©ploiement
```bash
# V√©rifier que le site est accessible
curl -I https://grandson-project.com

# V√©rifier le sitemap
curl https://grandson-project.com/sitemap.xml

# V√©rifier robots.txt
curl https://grandson-project.com/robots.txt
```

---

## üìà Rapports et Analyses

### G√©n√©rer un Rapport SEO
```bash
# Utiliser SEMrush API
curl "https://api.semrush.com/?type=domain_overview&domain=grandson-project.com&api_key=YOUR_API_KEY"

# Ou utiliser Ahrefs API
curl "https://api.ahrefs.com/v3/site-explorer/domain-rating?target=grandson-project.com&token=YOUR_API_KEY"
```

### Exporter les Donn√©es Google Search Console
```bash
# Utiliser Google Sheets avec Google Search Console Connector
# Ou utiliser l'API GSC

curl -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  "https://www.googleapis.com/webmasters/v3/sites/https%3A%2F%2Fgrandson-project.com%2F/searchAnalytics/query" \
  -X POST \
  -d '{"startDate":"2025-01-01","endDate":"2025-01-31","dimensions":["query","page"],"rowLimit":10000}' \
  > seo-report.json
```

---

## üêõ D√©pannage

### Probl√®me: Sitemap non trouv√©
```bash
# V√©rifier que le fichier existe
curl https://grandson-project.com/sitemap.xml

# V√©rifier les logs
npm run build 2>&1 | grep -i sitemap

# R√©g√©n√©rer
npm run build
```

### Probl√®me: Robots.txt non trouv√©
```bash
# V√©rifier que le fichier existe
curl https://grandson-project.com/robots.txt

# V√©rifier les logs
npm run build 2>&1 | grep -i robots

# R√©g√©n√©rer
npm run build
```

### Probl√®me: M√©tadonn√©es manquantes
```bash
# V√©rifier le layout.tsx
cat frontend/app/layout.tsx | grep -E 'metadata|title|description'

# V√©rifier les m√©tadonn√©es g√©n√©r√©es
curl -s https://grandson-project.com | grep -E '<title>|<meta'
```

### Probl√®me: Images non optimis√©es
```bash
# V√©rifier les images
curl -s https://grandson-project.com | grep -oP 'src="\K[^"]+' | head -5

# V√©rifier les formats
curl -I https://grandson-project.com/image.jpg | grep -i content-type
```

---

## üìö Ressources Utiles

### Documentation
- [Next.js SEO Guide](https://nextjs.org/learn/seo/introduction-to-seo)
- [Google Search Central](https://developers.google.com/search)
- [Schema.org Documentation](https://schema.org/)

### Outils en Ligne
- [Google Rich Results Test](https://search.google.com/test/rich-results)
- [Google PageSpeed Insights](https://pagespeed.web.dev/)
- [Google Mobile-Friendly Test](https://search.google.com/test/mobile-friendly)

### APIs
- [Google Search Console API](https://developers.google.com/webmaster-tools)
- [Google PageSpeed Insights API](https://developers.google.com/speed/docs/insights/v5/get-started)
- [SEMrush API](https://developer.semrush.com/)
- [Ahrefs API](https://ahrefs.com/api)

---

**Derni√®re mise √† jour:** D√©cembre 2025
**Version:** 1.0
